{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98e560ae",
   "metadata": {},
   "source": [
    "## Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dd3cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.colors import hsv_to_rgb\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Make sure that optimization is enabled\n",
    "if not cv.useOptimized():\n",
    "    cv.setUseOptimized(True)\n",
    "\n",
    "cv.useOptimized()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31966559",
   "metadata": {},
   "source": [
    "## Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f84a619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGroundtruths(path):\n",
    "    \"\"\"\n",
    "    this function is used to read annotations from the txt file\n",
    "    input: file path\n",
    "    output: annotations\n",
    "    \"\"\"\n",
    "    \n",
    "    annotations = []\n",
    "    \n",
    "    with open(path) as file:\n",
    "           for line in file:\n",
    "                row = line.strip().split(\";\")\n",
    "                annotations.append(row)\n",
    "                \n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14996dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hsv_segmentation(img):\n",
    "    \"\"\"\n",
    "    This function is used to perform HSV segmentation\n",
    "    input: image\n",
    "    output: mask of that image\n",
    "    \"\"\"\n",
    "    \n",
    "    # blur the image and convert the color range to HSV\n",
    "    kernel_size = 5\n",
    "    img_blur = cv.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "    hsv_img = cv.cvtColor(img_blur, cv.COLOR_BGR2HSV)\n",
    "    \n",
    "    # get mask\n",
    "    mask1 = cv.inRange(hsv_img, low_red, high_red)\n",
    "    mask2 = cv.inRange(hsv_img, low_red2, high_red2)\n",
    "    mask3 = cv.inRange(hsv_img, low_yellow, high_yellow)\n",
    "    mask4 = cv.inRange(hsv_img, low_blue, high_blue)\n",
    "    \n",
    "    # combine all the masks \n",
    "    combined_mask = cv.add(cv.add(cv.add(mask1, mask2), mask3), mask4)\n",
    "    \n",
    "    # opening morphology\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    combined_mask = cv.morphologyEx(combined_mask, cv.MORPH_OPEN, kernel, iterations=3)\n",
    "\n",
    "    return combined_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fa6b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findContour(mask):\n",
    "    \"\"\"\n",
    "    This function is used to find the largest contour\n",
    "    input: mask in gray scale\n",
    "    output: contour\n",
    "    \"\"\"\n",
    "    \n",
    "    mask_bgr = cv.cvtColor(mask, cv.COLOR_GRAY2BGR) \n",
    "    contours, _ = cv.findContours(mask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    #if no contour\n",
    "    if len(contours) == 0:\n",
    "        return None\n",
    "    \n",
    "    #find largest contour\n",
    "    length = []\n",
    "    for i in contours:\n",
    "        length.append(len(i))\n",
    "    max = np.argmax(length)\n",
    "    contour = contours[max]\n",
    "    \n",
    "    return contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1355f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGroundtruth(imgName, contour, annotations, resized_WH):\n",
    "    \"\"\"\n",
    "    this function is used to get predicted bounding box for original image size, actual bounding box and annotation for the image\n",
    "    input: image name, selected contour, annotations and width and height of the resized image\n",
    "    output: predicted and actual bounding box and the annotation of that image\n",
    "    \"\"\"\n",
    "    \n",
    "    #convert the bounding box of resized image to original image\n",
    "    for annotation in annotations:\n",
    "        if annotation[0] == imgName:\n",
    "            predict_XYWH = getOriSizeBBox(contour, annotation, resized_WH) \n",
    "            break\n",
    "\n",
    "    #get actual bounding box\n",
    "    (x,y,x2,y2) = (int(annotation[3]), int(annotation[4]), int(annotation[5]), int(annotation[6]))\n",
    "    w = x2 - x\n",
    "    h = y2 - y\n",
    "    truth_XYWH = (x,y,w,h)\n",
    "        \n",
    "    return predict_XYWH, truth_XYWH, annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd4e4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOriSizeBBox(contour, annotation, resized_WH):\n",
    "    \"\"\"\n",
    "    this function is used to convert bounding box of the resized image to the original image\n",
    "    input: contour, groundtruth, resized size\n",
    "    output: bounding box for original size image\n",
    "    \"\"\"\n",
    "    \n",
    "    #information of the original image\n",
    "    ori_width, ori_height = float(annotation[1]), float(annotation[2])\n",
    "    \n",
    "    #information of the resized image\n",
    "    x, y, w, h = cv.boundingRect(contour) #bounding box for resized image\n",
    "    resized_w, resized_h = resized_WH\n",
    "    \n",
    "    #calculate bounding box for original size image\n",
    "    width_ratio = float(ori_width/resized_w)\n",
    "    height_ratio = float(ori_height/resized_h)\n",
    "    x *= width_ratio\n",
    "    y *= height_ratio\n",
    "    w *= width_ratio\n",
    "    h *= height_ratio\n",
    "        \n",
    "    return (x,y,w,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454f0451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictXYWH, truth_XYWH, annotation):\n",
    "    \"\"\"\n",
    "    This function is used to calculate accuracy (Pixel accuracy, IoU), precision and recall\n",
    "    input: predicted and actual starting point, width and height, annotation\n",
    "    output: accuracy (pixel accuracy, IoU), precision and recall\n",
    "    \"\"\"\n",
    "    \n",
    "    # Exctract the value of 2 point of coordinates, width and height\n",
    "    predicted_x, predicted_y, predicted_w, predicted_h = predictXYWH\n",
    "    predicted_x2 = predicted_x + predicted_w\n",
    "    predicted_y2 = predicted_y + predicted_h\n",
    "    \n",
    "    truth_x, truth_y, truth_w, truth_h = truth_XYWH\n",
    "    truth_x2 = truth_x + truth_w\n",
    "    truth_y2 = truth_y + truth_h\n",
    "    \n",
    "    ori_width, ori_height = float(annotation[1]), float(annotation[2])\n",
    "    \n",
    "    # Find the point of overlap area\n",
    "    (x1, y1) = (max(predicted_x, truth_x), max(predicted_y, truth_y))  \n",
    "    (x2, y2) = (min(predicted_x2, truth_x2), min(predicted_y2, truth_y2)) \n",
    "    \n",
    "    # Calculate the area(overlapped, full image, predicted, actual and union)\n",
    "    overlapped_w = x2 - x1\n",
    "    overlapped_h = y2 - y1\n",
    "    if overlapped_w > 0 and overlapped_h > 0:\n",
    "        area_overlapped = overlapped_w * overlapped_h\n",
    "    else:\n",
    "        area_overlapped = 0\n",
    "    \n",
    "    area_img = ori_width * ori_height\n",
    "    area_pred = predicted_w * predicted_h\n",
    "    area_truth = truth_w * truth_h\n",
    "    area_union = area_pred + area_truth - area_overlapped\n",
    "    \n",
    "    # True negative, false positive and false negative\n",
    "    area_TN = area_img - area_union\n",
    "    area_FP = area_union - area_truth\n",
    "    area_FN = area_union - area_pred\n",
    "    \n",
    "    # Calculate the pixel accuracy, IoU, precision and recall\n",
    "    pixel_acc = (area_overlapped + area_TN) / (area_overlapped + area_TN + area_FP + area_FN)\n",
    "    IoU = area_overlapped / area_union\n",
    "    \n",
    "    if(area_overlapped != 0):\n",
    "        precision = area_overlapped / (area_overlapped + area_FP)\n",
    "        recall = area_overlapped / (area_overlapped + area_FN)\n",
    "    else:\n",
    "        precision, recall = 0, 0\n",
    "    \n",
    "    return IoU, pixel_acc, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c629dbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawBbox(img, xywh, color, thickness):\n",
    "    \"\"\"\n",
    "    This function is used to draw the bounding box (for showcasing)\n",
    "    input: img in BGR\n",
    "    output: img with bounding box\n",
    "    \"\"\"\n",
    "    \n",
    "    #if no contour\n",
    "    if xywh is None:\n",
    "        return img\n",
    "        \n",
    "    x, y, w, h = xywh\n",
    "    x = int(x)\n",
    "    y = int(y)\n",
    "    w = int(w)\n",
    "    h = int(h)\n",
    "    boundingBox = cv.rectangle(img, (x,y), (x+w, y+h), color, thickness)\n",
    "    return boundingBox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e6e096",
   "metadata": {},
   "source": [
    "## Run and segment all the images in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02784f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HSV color range\n",
    "low_red = np.array([0,40,30])\n",
    "high_red = np.array([5, 245, 255])\n",
    "low_red2 = np.array([119,40,30])\n",
    "high_red2 = np.array([179, 245, 255])\n",
    "low_yellow = np.array([10,117,100])\n",
    "high_yellow = np.array([40, 255, 255])\n",
    "low_blue = np.array([89,71,71])\n",
    "high_blue = np.array([125, 240, 190])\n",
    "\n",
    "# Locate the image folder path and the annotation file path\n",
    "current_dir = os.getcwd()\n",
    "img_path = os.path.join(current_dir, \"70 test images files\")\n",
    "path = os.path.join(current_dir, \"./TsignRecgTrain4170Annotation.txt\")\n",
    "annotations = readGroundtruths(path)\n",
    "\n",
    "# set variable to 0 for counting total and timestamp the starting time\n",
    "total_acc, total_IoU, total_pre, total_re, count, passed_count, print_count = 0, 0, 0, 0, 0, 0, 0\n",
    "first_hstack = False\n",
    "start_time = time.time()\n",
    "interval = start_time\n",
    "output, vertical = [], []\n",
    "\n",
    "# loop through the images inside the folder\n",
    "for filename in os.listdir(img_path):\n",
    "        img = cv.imread(os.path.join(img_path,filename))\n",
    "        if img is not None:\n",
    "            # Resize the image\n",
    "            img_resized = cv.resize(img, (200,200), interpolation = cv.INTER_CUBIC)\n",
    "            img_ori = img_resized.copy()\n",
    "            w, h, _ = img_resized.shape\n",
    "            WH = (w, h)\n",
    "            \n",
    "            # Perform HSV color segmentation then Canny edge afterward\n",
    "            res = hsv_segmentation(img_resized)\n",
    "            edges = cv.Canny(res, 180, 255)\n",
    "            contour = findContour(edges)\n",
    "            \n",
    "            # calculate the accuracy\n",
    "            pred_XYWH, truth_XYWH, annotation = getGroundtruth(filename, contour, annotations, WH)\n",
    "            IoU, acc, precision, recall = accuracy(pred_XYWH, truth_XYWH, annotation)\n",
    "            total_acc += acc\n",
    "            total_IoU += IoU\n",
    "            total_pre += precision\n",
    "            total_re += recall\n",
    "            count += 1\n",
    "            print_count += 1\n",
    "            if(IoU > 0.8):\n",
    "                passed_count += 1\n",
    "                \n",
    "            # Draw the bounding box to show at the end of the code\n",
    "            x, y, w, h = cv.boundingRect(contour)\n",
    "            draw_XYWH = (x, y, w, h)\n",
    "            drawBbox(img_resized, draw_XYWH, (0,0,255), thickness=2)\n",
    "            \n",
    "            # Append the images into one\n",
    "            append_image = np.hstack((img_ori, img_resized))\n",
    "            if (print_count == 1):\n",
    "                vertical = append_image\n",
    "            else:\n",
    "                vertical = np.vstack((vertical, append_image))\n",
    "                if (print_count == 10):\n",
    "                    if (first_hstack == False):\n",
    "                        output = vertical\n",
    "                        first_hstack = True\n",
    "                    else:\n",
    "                        output = np.hstack((output, vertical))\n",
    "                    print_count = 0;\n",
    "            \n",
    "            # print the accuracy and computing time\n",
    "            print(count, \"\\tAccuracy(Pixel, IoU):\", format((acc*100), \".2f\"), \"%, \", format((IoU*100), \".2f\"), \"%\", \"\\tComputing time:\", time.time() - interval)\n",
    "            interval = time.time()         \n",
    "\n",
    "# calculate the average    \n",
    "avg_acc = (total_acc / count)*100\n",
    "avg_IoU = (total_IoU / count)*100\n",
    "avg_pre = (total_pre / count)*100\n",
    "avg_re = (total_re / count)*100\n",
    "f_score = 2 * avg_pre* avg_re / (avg_pre + avg_re)\n",
    "\n",
    "# Print out the result\n",
    "print(\"Average (Pixel, IoU, precision, recall):\", format(avg_acc, \".2f\"), \"%, \", format(avg_IoU, \".2f\"), \"%, \",  \n",
    "      format(avg_pre, \".2f\"), \"%, \", format(avg_re, \".2f\"), \"%\", \"  F-score:\",format(f_score, \".2f\"), \"%\", \n",
    "      \"\\nNumber of images passed 80% IoU:\", passed_count, \"  Total:\", count, \"  total computing time:\", format(interval - start_time, \".4f\"), \"seconds\")\n",
    "\n",
    "# write all the segmented result in one image\n",
    "cv.imwrite(os.path.join(current_dir, 'output.png'), output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6b0d0f",
   "metadata": {},
   "source": [
    "## Test the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ade97f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HSV color range\n",
    "low_red = np.array([0,40,30])\n",
    "high_red = np.array([5, 245, 255])\n",
    "low_red2 = np.array([119,40,30])\n",
    "high_red2 = np.array([179, 245, 255])\n",
    "low_yellow = np.array([10,117,100])\n",
    "high_yellow = np.array([40, 255, 255])\n",
    "low_blue = np.array([89,71,71])\n",
    "high_blue = np.array([125, 240, 190])\n",
    "\n",
    "# Locate the annotation file path and the image folder path\n",
    "current_dir = os.getcwd()\n",
    "path = os.path.join(current_dir, \"./TsignRecgTrain4170Annotation.txt\")\n",
    "annotations = readGroundtruths(path)\n",
    "\n",
    "img_path = os.path.join(current_dir, \"70 test images files\")\n",
    "imgName = \"006_0017.png\"\n",
    "img = cv.imread(os.path.join(img_path,imgName))\n",
    "img_ori = img.copy()\n",
    "\n",
    "# Resize the image\n",
    "img_resized = cv.resize(img, (200,200), interpolation = cv.INTER_CUBIC)\n",
    "w, h, _ = img_resized.shape\n",
    "WH = (w, h)\n",
    "\n",
    "# Perform HSV color segmentation then Canny edge afterward\n",
    "res = hsv_segmentation(img_resized)\n",
    "edges = cv.Canny(res, 180, 255)\n",
    "contour = findContour(edges)\n",
    "\n",
    "# calculate the accuracy\n",
    "pred_XYWH, truth_XYWH, annotation = getGroundtruth(imgName, contour, annotations, WH)\n",
    "IoU, acc, precision, recall = accuracy(pred_XYWH, truth_XYWH, annotation)\n",
    "\n",
    "print(\"accuracy (Pixel, IoU)\", format(acc*100, \".2f\"), \"%, \", format(IoU*100, \".2f\"), \"% \", \" precision:\", \n",
    "      format(precision*100, \".2f\"), \"% \", \" recall:\", format(recall*100, \".2f\"), \"% \",)\n",
    "\n",
    "drawBbox(img_ori, pred_XYWH, (0,0,255), thickness=2) #red = predicted\n",
    "drawBbox(img_ori, truth_XYWH, (0,255,0), thickness=2) #green = groundtruth\n",
    "append_image = np.hstack((img, img_ori))\n",
    "\n",
    "cv.imshow('img', append_image)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
